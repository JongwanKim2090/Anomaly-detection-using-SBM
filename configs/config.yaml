# @package _global_

# specify here default training configuration
defaults:
  - trainer: default.yaml
  - model: ddpm.yaml
  - datamodule: cifar10.yaml
  - experiment: null

  - hydra: default.yaml

  # enable color logging
  - override hydra/hydra_logging: colorlog
  - override hydra/job_logging: colorlog

work_dir: ${hydra:runtime.cwd}

# path to folder with data
data_dir: ${work_dir}/data/

callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "valid_loss"
    save_top_k: 2
    save_last: True
    mode: "min"
    dirpath: "checkpoints/"
    filename: "sample-{epoch:02d}"
  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "valid_loss"
    patience: 10000
    mode: "min"


logger:
  _target_: pytorch_lightning.loggers.wandb.WandbLogger
  project: "Anomaly detection based on SCORE SDE"
  save_dir: "."
  name: ${datamodule.name}_${model.score_configs.model_name}_${model.sde_configs.sde_name}
  tags: [
      "${datamodule.name}",
      "${model.score_configs.model_name}",
      "${model.sde_configs.sde_name}",
      "${model.sampler_configs.predictor_name}",
      "${model.sampler_configs.corrector_name}"
  ]

debug: False
print_config: True
ignore_warnings: True

enable_model_summary: Tru3e